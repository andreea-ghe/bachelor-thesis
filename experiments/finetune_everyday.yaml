MODEL_NAME: jigsaw_finetune_everyday
MODULE: experiments

PROJECT: jigsaw

DATASET: breaking_bad.all_piece_matching

# Adjust GPUS and BATCH_SIZE to your hardware
# With 1 GPU: BATCH_SIZE 4 should work (model is ~25MB)
# If you get OOM, try BATCH_SIZE 2
GPUS: [0]
BATCH_SIZE: 4
NUM_WORKERS: 4

TRAIN:
  NUM_EPOCHS: 100        # fine-tuning needs fewer epochs than training from scratch
  LR: 0.0001             # 10x lower than training from scratch (0.001)
  WEIGHT_DECAY: 0.
  WARMUP_RATIO: 0.
  LR_SCHEDULER: 'cosine'
  LR_DECAY: 100.
  VAL_EVERY: 5

CALLBACK:
  CHECKPOINT_MONITOR: val/mat_f1
  CHECKPOINT_MODE: max

DATA:
  SUBSET: everyday
  DATA_FN: 'everyday.{}.txt'
  MAX_NUM_PART: 20
  NUM_PC_POINTS: 5000
  SAMPLE_BY: area
  MIN_PART_POINT: 30
  FRACTURE_LABEL_THRESHOLD: 0.025

MODEL:
  PC_CLS_METHOD: multi
  LOSS:
    w_cls_loss: 1.0
    w_mat_loss: 1.0       # matching loss ON from epoch 0 (pre-trained model is ready)
    mat_epoch: 0
    w_rig_loss: 1.0
    rig_epoch: 30          # rigidity loss from epoch 30

# Point to extracted weights
WEIGHT_FILE: checkpoint/jigsaw_4x4_128_512_250e_cosine_everyday_weights.pt

# STATS is for eval
STATS: "./results/jigsaw_finetune_everyday/stats/eval"
